{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c8c36b7",
   "metadata": {},
   "source": [
    "# Training Pipeline\n",
    "Selects features, creates training data, trains and saves model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b8283e",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9738b04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import XGBRegressor, plot_importance\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import hopsworks\n",
    "from xgboost import XGBRegressor\n",
    "import joblib\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import seaborn as sns\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eab0401",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "root_dir = Path().absolute()\n",
    "# Strip subdirectories if the notebook started in any\n",
    "if root_dir.parts[-1:] == ('pipeline',):\n",
    "    root_dir = Path(*root_dir.parts[:-1])\n",
    "if root_dir.parts[-1:] == ('src',):\n",
    "    root_dir = Path(*root_dir.parts[:-1])\n",
    "root_dir = str(root_dir) \n",
    "\n",
    "os.chdir(root_dir)\n",
    "print(f\"Root dir: {Path.cwd()}\")\n",
    "\n",
    "from src.data_utils.ingest import *\n",
    "\n",
    "load_dotenv()\n",
    "hopsworks_key = os.getenv('HOPSWORKS_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30672a4e",
   "metadata": {},
   "source": [
    "## Connect to Hopsworks Feature Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbef611",
   "metadata": {},
   "outputs": [],
   "source": [
    "if hopsworks_key is not None:\n",
    "    os.environ['HOPSWORKS_API_KEY'] = hopsworks_key\n",
    "\n",
    "# If you are invited to someone else's Hopsworks project, write that project's name below\n",
    "project_name = None\n",
    "\n",
    "if project_name:\n",
    "    project = hopsworks.login(project=f'{project_name}')\n",
    "else:\n",
    "    project = hopsworks.login()\n",
    "    \n",
    "fs = project.get_feature_store()\n",
    "\n",
    "# Set up secrets here\n",
    "secrets = hopsworks.get_secrets_api()\n",
    "# ...\n",
    "# ...\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b2cf0e",
   "metadata": {},
   "source": [
    "### Retrieve Feature groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610cb425",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_fg = fs.get_feature_group(\n",
    "    name=\"delay_features_fg\",\n",
    "    version=1\n",
    ")\n",
    "\n",
    "labels_fg = fs.get_feature_group(\n",
    "    name=\"delay_labels_fg\",\n",
    "    version=1\n",
    ")\n",
    "\n",
    "features_df = features_fg.read(online=True)\n",
    "labels_df = labels_fg.read(online=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c0ee97",
   "metadata": {},
   "outputs": [],
   "source": [
    "## print info\n",
    "print(\"features_df info: \")\n",
    "print(features_df.info())\n",
    "print()\n",
    "print(labels_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1eab176",
   "metadata": {},
   "source": [
    "### Merge features and labels into a df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9f9d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "HORIZON = pd.Timedelta(minutes=20)\n",
    "TOLERANCE = pd.Timedelta(minutes=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37dc78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = features_df.reset_index(drop=True)\n",
    "labels_df = labels_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b4de85",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = features_df.sort_values([\"line\", \"timestamp\"])\n",
    "labels_df = labels_df.sort_values([\"line\", \"timestamp\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201a48c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df[\"target_time\"] = features_df[\"timestamp\"] + HORIZON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfca8757",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = features_df.sort_values([\"line\", \"target_time\"])\n",
    "labels_df = labels_df.sort_values([\"line\", \"timestamp\"])\n",
    "\n",
    "features_df = features_df.reset_index(drop=True)\n",
    "labels_df = labels_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5f9308",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = features_df['line'].unique()\n",
    "merged_list = []\n",
    "for line in lines:\n",
    "    features_line = features_df[features_df['line'] == line].sort_values(\"target_time\")\n",
    "    labels_line = labels_df[labels_df['line'] == line].sort_values(\"timestamp\")\n",
    "    merged_line = pd.merge_asof(\n",
    "        features_line,\n",
    "        labels_line,\n",
    "        left_on=\"target_time\",\n",
    "        right_on=\"timestamp\",\n",
    "        direction=\"forward\",\n",
    "        tolerance=TOLERANCE,\n",
    "        suffixes=(\"_feat\", \"_label\")\n",
    "    )\n",
    "    merged_list.append(merged_line)\n",
    "\n",
    "train_df = pd.concat([merged_list[0], merged_list[1], merged_list[2]], ignore_index=True)\n",
    "# print(train_df.info())\n",
    "# print(train_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3592ce5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.rename(columns={\n",
    "    \"timestamp_feat\": \"timestamp\",\n",
    "    \"avg_delay\": \"target\", \n",
    "    \"line_feat\": \"line\",\n",
    "})\n",
    "\n",
    "train_df = train_df.drop(columns=[\n",
    "    \"timestamp_str_feat\",\n",
    "    \"target_time\",\n",
    "    \"timestamp_label\",\n",
    "    \"timestamp_str_label\"\n",
    "])\n",
    "\n",
    "train_df = train_df[[\"timestamp\", \"line\", \"delay_60\", \"delay_30\", \"delay_current\", \"target\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc47ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train_df.iloc[40])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13249777",
   "metadata": {},
   "source": [
    "### Drop rows with nan values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc98ef2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train_df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9864f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.dropna(subset=['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cb6be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.dropna(subset=[\"delay_60\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16ee5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train_df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfbacc5",
   "metadata": {},
   "source": [
    "### Add day as feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d1ee75",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"day\"] = train_df[\"timestamp\"].dt.day_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a9d27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[[\"timestamp\", \"line\", \"day\", \"delay_60\", \"delay_30\", \"delay_current\", \"target\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b525f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612d5d31",
   "metadata": {},
   "source": [
    "### Encode line and day using LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bb86e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "line_encoder = LabelEncoder()\n",
    "train_df[\"line_encoded\"] = line_encoder.fit_transform(train_df[\"line\"])\n",
    "\n",
    "days_of_week = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n",
    "day_encoder = LabelEncoder()\n",
    "day_encoder.fit(days_of_week)\n",
    "train_df[\"day_encoded\"] = day_encoder.transform(train_df[\"day\"])\n",
    "\n",
    "if not os.path.exists(Path(\"model\")):\n",
    "    os.makedirs(\"model\", exist_ok=True)\n",
    "\n",
    "joblib.dump(line_encoder, \"model/line_encoder.pkl\")\n",
    "joblib.dump(day_encoder, \"model/day_encoder.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd42db81",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[[\"timestamp\", \"line_encoded\", \"day_encoded\", \"delay_60\", \"delay_30\", \"delay_current\", \"target\"]]\n",
    "# print(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592894db",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"timestamp_str\"] = train_df[\"timestamp\"].dt.strftime(\"%Y-%m-%dT%H:%M:%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b7049f",
   "metadata": {},
   "source": [
    "### Split data and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d0105c",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_time = pd.Timestamp(\"2026-01-03 23:13:00\")\n",
    "train_data = train_df[train_df['timestamp'] < split_time]\n",
    "test_data = train_df[train_df['timestamp'] >= split_time]\n",
    "\n",
    "X_train = train_data.drop(columns=['target', 'timestamp', 'timestamp_str']).reset_index(drop=True)\n",
    "y_train = train_data['target'].reset_index(drop=True)\n",
    "\n",
    "X_test = test_data.drop(columns=['target', 'timestamp', 'timestamp_str']).reset_index(drop=True)\n",
    "y_test = test_data['target'].reset_index(drop=True)\n",
    "\n",
    "# print(X_train)\n",
    "# print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19dc28a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MLP = MLPRegressor(\n",
    "    hidden_layer_sizes=(128, 32),\n",
    "    activation=\"relu\",\n",
    "    solver=\"adam\",\n",
    "    max_iter=500,\n",
    "    random_state=42,\n",
    "    learning_rate_init=0.05\n",
    ")\n",
    "MLP.fit(X_train, y_train)\n",
    "y_pred = MLP.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Test MSE: {mse:.3f}, R^2: {r2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1195bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb_model = XGBRegressor()\n",
    "\n",
    "# xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "# mse = mean_squared_error(y_test, y_pred)\n",
    "# r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# print(f\"MSE: {mse:.3f}, R^2: {r2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c7ef3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mr = project.get_model_registry()\n",
    "model_name = \"MLP\"\n",
    "joblib.dump(MLP, \"model/model.joblib\")\n",
    "\n",
    "model = mr.python.create_model(\n",
    "    name=model_name,\n",
    "    metrics={\"mse\": mse, \"r2\": r2},\n",
    "    description=\"MLP regressor for metro delay prediction\",\n",
    ")\n",
    "\n",
    "model.save(\"model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0d4f85",
   "metadata": {},
   "source": [
    "### Plot of feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cd84d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_importance(MLP)\n",
    "if not os.path.exists(Path(\"model/images\")):\n",
    "    os.mkdir(Path(\"model/images\"))\n",
    "feature_importance_path = Path(\"model/images/feature_importance.png\")\n",
    "plt.savefig(feature_importance_path)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571f56b6",
   "metadata": {},
   "source": [
    "### Model predictions vs true delays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ceccf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=y_test, y=y_pred)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "plt.xlabel(\"True avg_delay\")\n",
    "plt.ylabel(\"Predicted avg_delay\")\n",
    "plt.title(\"MLP Predicted vs True delays\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "air-quality",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
