{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc1460dc-51bb-44c6-a4ed-5edcf5394f86",
   "metadata": {},
   "source": [
    "# Fetch Historical Data\n",
    "Fetches historical data from the Trafiklab API Kollektivtrafikens Datalabb (KoDa)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ec7feb-ac1e-4ef4-91fc-fba0fe7228f5",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e0ed936-f1d5-4f2e-a3c1-3b98298b5cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root dir: C:\\Users\\royli\\Desktop\\Courses\\ID2223_Scalable_Machine_Learning_and_Deep_Learning\\Project\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "root_dir = Path().absolute()\n",
    "# Strip subdirectories if the notebook started in any\n",
    "if root_dir.parts[-1:] == ('pipeline',):\n",
    "    root_dir = Path(*root_dir.parts[:-1])\n",
    "if root_dir.parts[-1:] == ('src',):\n",
    "    root_dir = Path(*root_dir.parts[:-1])\n",
    "root_dir = str(root_dir) \n",
    "\n",
    "os.chdir(root_dir)\n",
    "print(f\"Root dir: {Path.cwd()}\")\n",
    "\n",
    "from datetime import date, timedelta\n",
    "from src.data_utils.filter import *\n",
    "from src.data_utils.ingest import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148c9cc9-6bf5-481d-83d8-cf6fa779b1f3",
   "metadata": {},
   "source": [
    "## Fetch Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708b3296-2725-4ba5-8d7a-408d0e9bc342",
   "metadata": {},
   "source": [
    "### Decide How Many Days in the Past to Fetch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3faa4909-0ea8-4282-bb39-bcb02aa64cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2025-12-10', '2025-12-09']\n"
     ]
    }
   ],
   "source": [
    "# Define the start date and how many days in the past including the start date to fetch\n",
    "# Start date must be yesterday or earlier\n",
    "number_of_days = 2\n",
    "start_date = date(2025, 12, 10)\n",
    "\n",
    "dates = [start_date - timedelta(days=i) for i in range(number_of_days)]\n",
    "dates = [d.strftime(\"%Y-%m-%d\") for d in dates]\n",
    "\n",
    "print(dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c554fd84-70ef-41d5-8802-4b1eae0282cd",
   "metadata": {},
   "source": [
    "### Fetch Static Data from Trafiklab's KoDa API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60bbb070-53f1-434a-9777-c1262a79e228",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m attempt \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_retries):\n\u001b[32m     10\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m         zip_file = \u001b[43mfetch_static\u001b[49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m         zip_dir = extract_zip(zip_file)\n\u001b[32m     13\u001b[39m         output_dir = txt_to_csv(zip_dir)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Courses\\ID2223_Scalable_Machine_Learning_and_Deep_Learning\\Project\\src\\data_utils\\ingest.py:28\u001b[39m, in \u001b[36mfetch_static\u001b[39m\u001b[34m(date, target_dir)\u001b[39m\n\u001b[32m     24\u001b[39m api_key = os.getenv(\u001b[33m\"\u001b[39m\u001b[33mKODA_API_KEY\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     26\u001b[39m url = \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mhttps://api.koda.trafiklab.se/KoDa/api/v2/gtfs-static/sl?date=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdate\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m&key=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mapi_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m response = \u001b[43mrequests\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m response.raise_for_status()\n\u001b[32m     31\u001b[39m file_path = os.path.join(target_dir, \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdate\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.zip\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\sl\\Lib\\site-packages\\requests\\api.py:73\u001b[39m, in \u001b[36mget\u001b[39m\u001b[34m(url, params, **kwargs)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget\u001b[39m(url, params=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m     63\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[32m     64\u001b[39m \n\u001b[32m     65\u001b[39m \u001b[33;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     70\u001b[39m \u001b[33;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mget\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\sl\\Lib\\site-packages\\requests\\api.py:59\u001b[39m, in \u001b[36mrequest\u001b[39m\u001b[34m(method, url, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m sessions.Session() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\sl\\Lib\\site-packages\\requests\\sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\sl\\Lib\\site-packages\\requests\\sessions.py:746\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    743\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m    745\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[32m--> \u001b[39m\u001b[32m746\u001b[39m     \u001b[43mr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcontent\u001b[49m\n\u001b[32m    748\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\sl\\Lib\\site-packages\\requests\\models.py:902\u001b[39m, in \u001b[36mResponse.content\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    900\u001b[39m         \u001b[38;5;28mself\u001b[39m._content = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    901\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m902\u001b[39m         \u001b[38;5;28mself\u001b[39m._content = \u001b[33;43mb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCONTENT_CHUNK_SIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    904\u001b[39m \u001b[38;5;28mself\u001b[39m._content_consumed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    905\u001b[39m \u001b[38;5;66;03m# don't need to release the connection; that's been handled by urllib3\u001b[39;00m\n\u001b[32m    906\u001b[39m \u001b[38;5;66;03m# since we exhausted the data.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\sl\\Lib\\site-packages\\requests\\models.py:820\u001b[39m, in \u001b[36mResponse.iter_content.<locals>.generate\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    818\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.raw, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    819\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m820\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m.raw.stream(chunk_size, decode_content=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    821\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    822\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\sl\\Lib\\site-packages\\urllib3\\response.py:1253\u001b[39m, in \u001b[36mHTTPResponse.stream\u001b[39m\u001b[34m(self, amt, decode_content)\u001b[39m\n\u001b[32m   1247\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1248\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m (\n\u001b[32m   1249\u001b[39m         \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m._fp)\n\u001b[32m   1250\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._decoded_buffer) > \u001b[32m0\u001b[39m\n\u001b[32m   1251\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._decoder \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._decoder.has_unconsumed_tail)\n\u001b[32m   1252\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1253\u001b[39m         data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m=\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1255\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[32m   1256\u001b[39m             \u001b[38;5;28;01myield\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\sl\\Lib\\site-packages\\urllib3\\response.py:1108\u001b[39m, in \u001b[36mHTTPResponse.read\u001b[39m\u001b[34m(self, amt, decode_content, cache_content)\u001b[39m\n\u001b[32m   1105\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._decoded_buffer) >= amt:\n\u001b[32m   1106\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._decoded_buffer.get(amt)\n\u001b[32m-> \u001b[39m\u001b[32m1108\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raw_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1110\u001b[39m flush_decoder = amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (amt != \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data)\n\u001b[32m   1112\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   1113\u001b[39m     \u001b[38;5;129;01mnot\u001b[39;00m data\n\u001b[32m   1114\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._decoded_buffer) == \u001b[32m0\u001b[39m\n\u001b[32m   1115\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._decoder \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._decoder.has_unconsumed_tail)\n\u001b[32m   1116\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\sl\\Lib\\site-packages\\urllib3\\response.py:1024\u001b[39m, in \u001b[36mHTTPResponse._raw_read\u001b[39m\u001b[34m(self, amt, read1)\u001b[39m\n\u001b[32m   1021\u001b[39m fp_closed = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m._fp, \u001b[33m\"\u001b[39m\u001b[33mclosed\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1023\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._error_catcher():\n\u001b[32m-> \u001b[39m\u001b[32m1024\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fp_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mread1\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fp_closed \u001b[38;5;28;01melse\u001b[39;00m \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1025\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt != \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n\u001b[32m   1026\u001b[39m         \u001b[38;5;66;03m# Platform-specific: Buggy versions of Python.\u001b[39;00m\n\u001b[32m   1027\u001b[39m         \u001b[38;5;66;03m# Close the connection when no data is returned\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1032\u001b[39m         \u001b[38;5;66;03m# not properly close the connection in all cases. There is\u001b[39;00m\n\u001b[32m   1033\u001b[39m         \u001b[38;5;66;03m# no harm in redundantly calling close.\u001b[39;00m\n\u001b[32m   1034\u001b[39m         \u001b[38;5;28mself\u001b[39m._fp.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\sl\\Lib\\site-packages\\urllib3\\response.py:1007\u001b[39m, in \u001b[36mHTTPResponse._fp_read\u001b[39m\u001b[34m(self, amt, read1)\u001b[39m\n\u001b[32m   1004\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fp.read1(amt) \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fp.read1()\n\u001b[32m   1005\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1006\u001b[39m     \u001b[38;5;66;03m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1007\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fp.read()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\sl\\Lib\\http\\client.py:479\u001b[39m, in \u001b[36mHTTPResponse.read\u001b[39m\u001b[34m(self, amt)\u001b[39m\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.length \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt > \u001b[38;5;28mself\u001b[39m.length:\n\u001b[32m    477\u001b[39m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[32m    478\u001b[39m     amt = \u001b[38;5;28mself\u001b[39m.length\n\u001b[32m--> \u001b[39m\u001b[32m479\u001b[39m s = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[32m    481\u001b[39m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[32m    482\u001b[39m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[32m    483\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_conn()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\sl\\Lib\\socket.py:720\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    718\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    719\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m720\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    721\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    722\u001b[39m         \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\sl\\Lib\\ssl.py:1251\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1247\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1248\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1249\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1250\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1251\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1252\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1253\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\sl\\Lib\\ssl.py:1103\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1101\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1102\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1103\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1104\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1105\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "DATA_ROOT = Path('data')\n",
    "for d in dates:\n",
    "    date_dir = Path(f\"data/static/{d}\")\n",
    "    if date_dir.exists():\n",
    "        print(f\"{d} exists, skipping\")\n",
    "        continue\n",
    "        \n",
    "    max_retries = 10\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            zip_file = fetch_static(d, \"data\")\n",
    "            zip_dir = extract_zip(zip_file)\n",
    "            output_dir = txt_to_csv(zip_dir)\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"Attempt {attempt} failed: {e}\")\n",
    "            if attempt == max_retries - 1:\n",
    "                print(\"Reached max retries, skipping date\")\n",
    "                \n",
    "            sleep_time = 5\n",
    "            print(f\"Retrying in {sleep_time}s...\")\n",
    "            time.sleep(sleep_time)\n",
    "    else:\n",
    "        print(f'Download failed for date {d}')\n",
    "        break\n",
    "    filter_irrelevant_files(output_dir, date)\n",
    "    filter_static_data_for_date(output_dir, date)\n",
    "print(\"Finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd01415d-d387-4ca3-a821-270eb55ddbf2",
   "metadata": {},
   "source": [
    "### Fetch Realtime VehiclePositions Data from Trafiklab's KoDa API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbaa614-117c-4ae1-8e6a-89ceba0e8d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching realtime VehiclePositions data for 2025-12-10\n",
      "Saved GTFS realtime file to data\\2025-12-10.7z.\n",
      "Successfully extracted data\\2025-12-10.7z to data\\realtime\\2025-12-10\\VehiclePositions\\raw\n",
      "Removed data\\2025-12-10.7z\n",
      "Successfully flattened data\\realtime\\2025-12-10\\VehiclePositions\\raw\n",
      "Fetching realtime VehiclePositions data for 2025-12-09\n",
      "[1/65] Still processing, retrying connection in 60 seconds\n",
      "[2/65] Still processing, retrying connection in 60 seconds\n",
      "[3/65] Still processing, retrying connection in 60 seconds\n",
      "[4/65] Still processing, retrying connection in 60 seconds\n",
      "[5/65] Still processing, retrying connection in 60 seconds\n",
      "[6/65] Still processing, retrying connection in 60 seconds\n",
      "[7/65] Still processing, retrying connection in 60 seconds\n",
      "[8/65] Still processing, retrying connection in 60 seconds\n",
      "[9/65] Still processing, retrying connection in 60 seconds\n",
      "[10/65] Still processing, retrying connection in 60 seconds\n",
      "[11/65] Still processing, retrying connection in 60 seconds\n",
      "[12/65] Still processing, retrying connection in 60 seconds\n",
      "[13/65] Still processing, retrying connection in 60 seconds\n",
      "[14/65] Still processing, retrying connection in 60 seconds\n",
      "[15/65] Still processing, retrying connection in 60 seconds\n",
      "[16/65] Still processing, retrying connection in 60 seconds\n",
      "[17/65] Still processing, retrying connection in 60 seconds\n",
      "[18/65] Still processing, retrying connection in 60 seconds\n",
      "[19/65] Still processing, retrying connection in 60 seconds\n",
      "[20/65] Still processing, retrying connection in 60 seconds\n",
      "[21/65] Still processing, retrying connection in 60 seconds\n",
      "[22/65] Still processing, retrying connection in 60 seconds\n",
      "[23/65] Still processing, retrying connection in 60 seconds\n",
      "[24/65] Still processing, retrying connection in 60 seconds\n",
      "[25/65] Still processing, retrying connection in 60 seconds\n",
      "[26/65] Still processing, retrying connection in 60 seconds\n",
      "[27/65] Still processing, retrying connection in 60 seconds\n",
      "[28/65] Still processing, retrying connection in 60 seconds\n",
      "[29/65] Still processing, retrying connection in 60 seconds\n",
      "[30/65] Still processing, retrying connection in 60 seconds\n",
      "[31/65] Still processing, retrying connection in 60 seconds\n",
      "[32/65] Still processing, retrying connection in 60 seconds\n",
      "[33/65] Still processing, retrying connection in 60 seconds\n",
      "[34/65] Still processing, retrying connection in 60 seconds\n",
      "[35/65] Still processing, retrying connection in 60 seconds\n",
      "[36/65] Still processing, retrying connection in 60 seconds\n",
      "[37/65] Still processing, retrying connection in 60 seconds\n",
      "[38/65] Still processing, retrying connection in 60 seconds\n",
      "[39/65] Still processing, retrying connection in 60 seconds\n",
      "[40/65] Still processing, retrying connection in 60 seconds\n",
      "[41/65] Still processing, retrying connection in 60 seconds\n",
      "[42/65] Still processing, retrying connection in 60 seconds\n",
      "[43/65] Still processing, retrying connection in 60 seconds\n",
      "[44/65] Still processing, retrying connection in 60 seconds\n",
      "[45/65] Still processing, retrying connection in 60 seconds\n",
      "[46/65] Still processing, retrying connection in 60 seconds\n",
      "[47/65] Still processing, retrying connection in 60 seconds\n",
      "[48/65] Still processing, retrying connection in 60 seconds\n",
      "[49/65] Still processing, retrying connection in 60 seconds\n",
      "[50/65] Still processing, retrying connection in 60 seconds\n",
      "[51/65] Still processing, retrying connection in 60 seconds\n",
      "[52/65] Still processing, retrying connection in 60 seconds\n",
      "[53/65] Still processing, retrying connection in 60 seconds\n",
      "[54/65] Still processing, retrying connection in 60 seconds\n",
      "[55/65] Still processing, retrying connection in 60 seconds\n",
      "[56/65] Still processing, retrying connection in 60 seconds\n",
      "[57/65] Still processing, retrying connection in 60 seconds\n",
      "[58/65] Still processing, retrying connection in 60 seconds\n",
      "[59/65] Still processing, retrying connection in 60 seconds\n",
      "[60/65] Still processing, retrying connection in 60 seconds\n",
      "[61/65] Still processing, retrying connection in 60 seconds\n",
      "[62/65] Still processing, retrying connection in 60 seconds\n",
      "[63/65] Still processing, retrying connection in 60 seconds\n",
      "[64/65] Still processing, retrying connection in 60 seconds\n",
      "[65/65] Still processing, retrying connection in 60 seconds\n",
      "Max retries reached, skipping date 2025-12-09\n",
      "Finished fetching realtime VehiclePositions data\n"
     ]
    }
   ],
   "source": [
    "for d in dates:\n",
    "    date_dir = Path(f\"data/realtime/{d}/VehiclePositions\")\n",
    "    if date_dir.exists():\n",
    "        print(f\"{d} exists, skipping\")\n",
    "        continue\n",
    "\n",
    "    print(f\"Fetching realtime VehiclePositions data for {d}\")\n",
    "    realtime_file = fetch_realtime(d, \"data\", feed='VehiclePositions')\n",
    "    if realtime_file is not None:\n",
    "        extracted = extract_7z(realtime_file, feed='VehiclePositions')\n",
    "        raw_dir = flatten_extracted_structure(extracted)\n",
    "        preprocess_and_aggregate_VP(raw_dir, d)\n",
    "\n",
    "print(\"Finished fetching realtime VehiclePositions data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2a413c-133c-4234-826a-446d8e2ddbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in dates:\n",
    "    date_dir = Path(f\"data/realtime/{d}/TripUpdates\")\n",
    "    if date_dir.exists():\n",
    "        print(f\"{d} exists, skipping\")\n",
    "        continue\n",
    "\n",
    "    print(f\"Fetching realtime TripUpdates data for {d}\")\n",
    "    realtime_file = fetch_realtime(d, \"data\", feed='TripUpdates')\n",
    "    if realtime_file is not None:\n",
    "        extracted = extract_7z(realtime_file, feed='TripUpdates')\n",
    "        raw_dir = flatten_extracted_structure(extracted)\n",
    "        preprocess_and_aggregate_TU(raw_dir, d)\n",
    "\n",
    "print(\"Finished fetching realtime TripUpdates data\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (SL)",
   "language": "python",
   "name": "sl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
