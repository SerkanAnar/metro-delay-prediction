{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "051a027d-5e21-4d6c-8223-ada059f217da",
   "metadata": {},
   "source": [
    "# Inference Pipeline\n",
    "Predicts delays for the next hour given delays from the last three 30 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533578c4-c9bb-4ad2-8319-1fc159dc279d",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba8bea68-2b57-4854-b91d-77bd3818a119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root dir: /Users/serkan/ID2223-project\n"
     ]
    }
   ],
   "source": [
    "from datetime import date\n",
    "import hopsworks\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import joblib\n",
    "import time\n",
    "\n",
    "root_dir = Path().absolute()\n",
    "# Strip subdirectories if the notebook started in any\n",
    "if root_dir.parts[-1:] == ('pipeline',):\n",
    "    root_dir = Path(*root_dir.parts[:-1])\n",
    "if root_dir.parts[-1:] == ('src',):\n",
    "    root_dir = Path(*root_dir.parts[:-1])\n",
    "root_dir = str(root_dir) \n",
    "\n",
    "os.chdir(root_dir)\n",
    "print(f\"Root dir: {Path.cwd()}\")\n",
    "\n",
    "from src.data_utils.plots import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29dc0a23-5d52-4ca4-b7d0-8d4dccd9e8c1",
   "metadata": {},
   "source": [
    "### Connect to Hopsworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0bc7f9f7-5c3d-47b3-adca-ada45a5ce2af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-05 16:19:12,155 INFO: Closing external client and cleaning up certificates.\n",
      "Connection closed.\n",
      "2026-01-05 16:19:12,160 INFO: Initializing external client\n",
      "2026-01-05 16:19:12,160 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "2026-01-05 16:19:12,824 WARNING: UserWarning: The installed hopsworks client version 4.4.2 may not be compatible with the connected Hopsworks backend version 4.2.2. \n",
      "To ensure compatibility please install the latest bug fix release matching the minor version of your backend (4.2) by running 'pip install hopsworks==4.2.*'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-05 16:19:14,054 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1330333\n"
     ]
    }
   ],
   "source": [
    "# Enter the project name if the project in Hopsworks is not your main project\n",
    "#project_name = None\n",
    "project_name = 'metro_delay_prediction'\n",
    "max_retries = 3\n",
    "for i in range(max_retries):\n",
    "    try:\n",
    "        if project_name:\n",
    "            project = hopsworks.login(project=f'{project_name}')\n",
    "        else:\n",
    "            project = hopsworks.login()\n",
    "        fs = project.get_feature_store()\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(f'Error {e}, retrying in 1 second')\n",
    "        time.sleep(1)\n",
    "else:\n",
    "    raise RuntimeError(f'Failed to connect to hopsworks')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae08cdc-a3bf-4c1b-b001-327c2d1fc31a",
   "metadata": {},
   "source": [
    "### Retrieve Model from Model Registry and load model + artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd0b6547-f678-4224-a1fe-350326156d17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb94fe9cc85a468487eddfd25e90957a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.000%|          | 0/125071 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model artifact (0 dirs, 1 files)... \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ded3afe5e424d0d9e97e3b1146295e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.000%|          | 0/517 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model artifact (0 dirs, 2 files)... \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a0bbb21e80f418f9ce08267d4a3490d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.000%|          | 0/21293 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model artifact (1 dirs, 3 files)... \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8b37e1c2e3f408f99d7024040290b2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading: 0.000%|          | 0/579 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model artifact (1 dirs, 4 files)... DONE\r"
     ]
    }
   ],
   "source": [
    "max_retries = 3\n",
    "for i in range(max_retries):\n",
    "    try:\n",
    "        mr = project.get_model_registry()\n",
    "        retrieved_model = mr.get_model(name='MLP', version=1)\n",
    "\n",
    "        model_dir = retrieved_model.download()\n",
    "\n",
    "        # fv = retrieved_model.get_feature_view()\n",
    "        # saved_dir = retrieved_model.download()\n",
    "        MLP = joblib.load(f'{model_dir}/model.joblib')\n",
    "        line_encoder = joblib.load(f'{model_dir}/line_encoder.pkl')\n",
    "        day_encoder = joblib.load(f'{model_dir}/day_encoder.pkl')\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(f'Error {e}, retrying in 1 second')\n",
    "        time.sleep(1)\n",
    "else:\n",
    "    raise RuntimeError(f'Failed to get model and artifacts.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe30ddb3-6e09-4a63-866d-399d2243c692",
   "metadata": {},
   "source": [
    "### Fetch features and take most recent data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "634a409a",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_retries = 3\n",
    "for i in range(max_retries):\n",
    "    try:\n",
    "        features_fg = fs.get_feature_group(\n",
    "            name=\"features_fg\",\n",
    "            version=1\n",
    "        )\n",
    "        features_df = features_fg.read(online=True)\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(f'Error {e}, retrying in 1 second')\n",
    "        time.sleep(1)\n",
    "else:\n",
    "    raise RuntimeError(f'Failed to get features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b6d9548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            timestamp        timestamp_str          line   delay_60  \\\n",
      "0 2026-01-04 15:42:00  2026-01-04T15:42:00    Blå linjen -38.000000   \n",
      "1 2026-01-04 15:42:00  2026-01-04T15:42:00  Gröna linjen  53.451613   \n",
      "2 2026-01-04 15:42:00  2026-01-04T15:42:00   Röda linjen  -1.200000   \n",
      "\n",
      "    delay_30  delay_current  \n",
      "0 -24.916667         -32.25  \n",
      "1  54.903226          51.10  \n",
      "2  -8.200000         -13.92  \n"
     ]
    }
   ],
   "source": [
    "latest_df = features_df.sort_values(\"timestamp\").groupby(\"line\").tail(1).reset_index(drop=True)\n",
    "print(latest_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332dc8dd",
   "metadata": {},
   "source": [
    "### Encode non-numerical features and set up data for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "888640c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-05 16:19:42,797 WARNING: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "\n",
      "2026-01-05 16:19:42,798 WARNING: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "\n",
      "2026-01-05 16:19:42,799 WARNING: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "\n",
      "2026-01-05 16:19:42,800 WARNING: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "\n",
      "            timestamp        timestamp_str          line   delay_60  \\\n",
      "0 2026-01-04 15:42:00  2026-01-04T15:42:00    Blå linjen -38.000000   \n",
      "1 2026-01-04 15:42:00  2026-01-04T15:42:00  Gröna linjen  53.451613   \n",
      "2 2026-01-04 15:42:00  2026-01-04T15:42:00   Röda linjen  -1.200000   \n",
      "\n",
      "    delay_30  delay_current     day  day_encoded  line_encoded  \n",
      "0 -24.916667         -32.25  Sunday            3             0  \n",
      "1  54.903226          51.10  Sunday            3             1  \n",
      "2  -8.200000         -13.92  Sunday            3             2  \n"
     ]
    }
   ],
   "source": [
    "latest_df[\"day\"] = latest_df[\"timestamp\"].dt.day_name()\n",
    "latest_df[\"day_encoded\"] = day_encoder.transform(latest_df[\"day\"])\n",
    "latest_df[\"line_encoded\"] = line_encoder.transform(latest_df[\"line\"])\n",
    "print(latest_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9106504e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   line_encoded  day_encoded   delay_60   delay_30  delay_current\n",
      "0             0            3 -38.000000 -24.916667         -32.25\n",
      "1             1            3  53.451613  54.903226          51.10\n",
      "2             2            3  -1.200000  -8.200000         -13.92\n"
     ]
    }
   ],
   "source": [
    "inference_df = latest_df[[\"line_encoded\", \"day_encoded\", \"delay_60\", \"delay_30\", \"delay_current\"]].copy()\n",
    "X = inference_df.dropna(subset=[\"delay_60\", \"delay_30\", \"delay_current\"]).reset_index(drop=True)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f8195f",
   "metadata": {},
   "source": [
    "### Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7266ddc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-05 16:19:49,973 WARNING: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "\n",
      "2026-01-05 16:19:49,974 WARNING: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "\n",
      "2026-01-05 16:19:49,975 WARNING: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "\n",
      "[-30.356695  51.729263  -9.12046 ]\n"
     ]
    }
   ],
   "source": [
    "preds = MLP.predict(X).astype(\"float32\")\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c02e7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_df[\"line\"] = line_encoder.inverse_transform(inference_df[\"line_encoded\"])\n",
    "inference_df[\"prediction\"] = preds\n",
    "inference_df[\"timestamp\"] = latest_df[\"timestamp\"]\n",
    "inference_df[\"timestamp_pk\"] = inference_df[\"timestamp\"].dt.strftime(\"%Y-%m-%dT%H:%M:%S\")\n",
    "inference_df[\"delay_hind\"] = latest_df[\"delay_current\"]\n",
    "result = inference_df[[\"line\", \"timestamp\", \"timestamp_pk\", \"prediction\", \"delay_hind\"]]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbb783b",
   "metadata": {},
   "source": [
    "### Upload predictions to hopsworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f57510",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_retries = 3\n",
    "for i in range(max_retries):\n",
    "    try:\n",
    "        monitor_fg = fs.get_or_create_feature_group(\n",
    "            name='sl_prediction',\n",
    "            description='SL metro lines prediction monitoring',\n",
    "            version=1,\n",
    "            primary_key=['line', 'timestamp_pk'],\n",
    "            event_time='timestamp',\n",
    "        )\n",
    "        monitor_fg.insert(result, wait=True)\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(f'Error {e}, retrying in 1 second')\n",
    "        time.sleep(1)\n",
    "else:\n",
    "    raise RuntimeError(f'Failed to insert to monitor feature group')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e372a381",
   "metadata": {},
   "source": [
    "### Get all predictions and update plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c123afc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_retries = 3\n",
    "for i in range(max_retries):\n",
    "    try:\n",
    "        predictions_fg = fs.get_feature_group(\n",
    "            name=\"sl_prediction\",\n",
    "            version=1\n",
    "        )\n",
    "        predictions_df = predictions_fg.read()\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(f'Error {e}, retrying in 1 second')\n",
    "        time.sleep(1)\n",
    "else:\n",
    "    raise RuntimeError(f'Failed to read predictions feature group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423f4df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path = Path('docs/images/')\n",
    "plot_metro_delay_predictions(predictions_df, images_path, hindcast=True)\n",
    "plot_metro_delay_predictions(predictions_df, images_path, hindcast=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "air-quality",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
